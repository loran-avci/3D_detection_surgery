# 3Automated image labeling and marker-less deep-learning-based 3D detection for surgical wires

Augmented reality in surgery is becoming increasingly essential to support surgeons. Larger surgical tools are already detected to support the surgeon’s work, but
smaller objects are still mostly neglected. Surgical wires, called K-wires, are used in various surgical disciplines. The tracking of K-wires would thus facilitate computerassisted
surgical navigation. We propose a novel markerless concept for tracking K-wires that can be used for surgical navigation. Our system generates an unlimited
amount of annotated stereo image data quickly. By applying deep learning methods, the acquired data can be leveraged to detect the K-wires. The system has been
developed and evaluated on a lumbosacral spine phantom. Our method achieved a mean error of 6.50 ± 2.30mmand 6.40 ± 3.69° in the marker-less ground-truth generation.
The deep learning-based markerless K-wire detection for computer-generated images achieved a mean error of 6.11 mm ± 1.33 mm to the ground truth labels. Our
results show that our markerless image labeling method can be used in the future to generate large amounts of data with good quality. Although we could not evaluate
the detection of K-wires with the recorded data due to inadequate stereo encoding, we have shown that our stereo neural network performs well in marker-free detection
for computer-generated images.

![image](https://user-images.githubusercontent.com/54269003/188913968-4e376435-11d2-419a-9c9f-ce892bc310a5.png)


